{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4b23f851",
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from seqfacben.generators.random import RandomSequenceGenerator\n",
        "from seqfacben.tasks.sorting import SortingTask\n",
        "from seqfacben.models.simple_nn import SimpleNN\n",
        "from seqfacben.manager.task_manager import TaskManager\n",
        "from seqfacben.losses.sequence import cross_entropy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c41410d8",
      "metadata": {},
      "source": [
        "##### I. Single Combination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "983affb1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1000: loss = 1.2891, acc = 0.5312\n",
            "Step 2000: loss = 0.9713, acc = 0.6729\n",
            "Step 3000: loss = 0.6739, acc = 0.7622\n",
            "Step 4000: loss = 0.5744, acc = 0.8027\n",
            "Step 5000: loss = 0.4823, acc = 0.8179\n",
            "\n",
            "Testing:\n",
            "Final accuracy: 0.7954\n",
            "\n",
            "Examples:\n",
            "\n",
            "Example 1:\n",
            "  Input:  [37, 10, 36, 23, 15, 25, 41, 3, 27, 41, 19, 43, 58, 39, 16, 40, 59, 47, 40, 33, 51, 10, 38, 4, 29, 15, 14, 62, 54, 33, 34, 48]\n",
            "  Target: [3, 4, 10, 10, 14, 15, 15, 16, 19, 23, 25, 27, 29, 33, 33, 34, 36, 37, 38, 39, 40, 40, 41, 41, 43, 47, 48, 51, 54, 58, 59, 62]\n",
            "  Pred:   [3, 4, 10, 10, 14, 15, 15, 16, 19, 23, 26, 27, 30, 33, 33, 34, 36, 37, 38, 39, 40, 40, 41, 43, 43, 47, 48, 51, 54, 58, 59, 62]\n",
            "  Correct: 29/32\n",
            "\n",
            "Example 2:\n",
            "  Input:  [30, 30, 32, 37, 61, 47, 43, 15, 29, 50, 44, 19, 11, 63, 14, 42, 43, 35, 47, 38, 61, 10, 53, 33, 59, 37, 60, 21, 63, 39, 37, 52]\n",
            "  Target: [10, 11, 14, 15, 19, 21, 29, 30, 30, 32, 33, 35, 37, 37, 37, 38, 39, 42, 43, 43, 44, 47, 47, 50, 52, 53, 59, 60, 61, 61, 63, 63]\n",
            "  Pred:   [10, 11, 13, 19, 26, 19, 30, 30, 30, 30, 32, 33, 37, 37, 38, 37, 39, 42, 43, 43, 45, 46, 47, 50, 52, 52, 59, 59, 60, 61, 63, 63]\n",
            "  Correct: 17/32\n",
            "\n",
            "Example 3:\n",
            "  Input:  [50, 53, 9, 30, 21, 51, 44, 35, 18, 14, 15, 47, 3, 60, 17, 46, 14, 23, 2, 17, 5, 61, 36, 18, 12, 31, 11, 56, 23, 59, 44, 56]\n",
            "  Target: [2, 3, 5, 9, 11, 12, 14, 14, 15, 17, 17, 18, 18, 21, 23, 23, 30, 31, 35, 36, 44, 44, 46, 47, 50, 51, 53, 56, 56, 59, 60, 61]\n",
            "  Pred:   [2, 3, 5, 9, 11, 12, 14, 14, 14, 17, 17, 18, 18, 23, 23, 23, 29, 31, 35, 36, 44, 44, 44, 47, 50, 51, 53, 56, 56, 59, 60, 61]\n",
            "  Correct: 28/32\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Generator parameters\n",
        "vocab_size = 64\n",
        "seq_len = 32\n",
        "\n",
        "# Model parameters\n",
        "d_model = 64\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 64\n",
        "train_steps = 5000\n",
        "\n",
        "# Set up and train\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "generator = RandomSequenceGenerator(seq_len, vocab_size)\n",
        "task = SortingTask(generator, loss_fn=cross_entropy)\n",
        "model = SimpleNN(vocab_size, seq_len, d_model=d_model).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "manager = TaskManager(task, model, optimizer, device)\n",
        "\n",
        "# Train\n",
        "manager.train(n_steps=train_steps, batch_size=batch_size)\n",
        "\n",
        "# Test\n",
        "print(\"\\nTesting:\")\n",
        "val_loss, val_acc = manager.eval_step(batch_size=batch_size)\n",
        "print(f\"Final val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
        "\n",
        "manager.show_examples(n_examples=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bdb8dfa",
      "metadata": {},
      "source": [
        "##### II. Multi Experiment Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd5480c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Experiment configurations\n",
        "configs = [\n",
        "    {'vocab_size': 5, 'seq_len': 10},\n",
        "    {'vocab_size': 10, 'seq_len': 10},\n",
        "    {'vocab_size': 20, 'seq_len': 10},\n",
        "    {'vocab_size': 5, 'seq_len': 20},\n",
        "    {'vocab_size': 5, 'seq_len': 30},\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for config in configs:\n",
        "    vocab_size = config['vocab_size']\n",
        "    seq_len = config['seq_len']\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running: vocab_size={vocab_size}, seq_len={seq_len}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Setup\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    generator = RandomSequenceGenerator(seq_len, vocab_size)\n",
        "    task = SortingTask(generator, loss_fn=cross_entropy)\n",
        "    model = SimpleNN(vocab_size, seq_len, d_model=64).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    manager = TaskManager(task, model, optimizer, device)\n",
        "    \n",
        "    # Train\n",
        "    history = manager.train(n_steps=10000, batch_size=32, eval_every=500)\n",
        "    \n",
        "    # Final evaluation\n",
        "    val_loss, val_acc = manager.eval_step(batch_size=256)\n",
        "    \n",
        "    # Save results\n",
        "    last = history[-1] if history else {}\n",
        "    results.append({\n",
        "        'vocab_size': vocab_size,\n",
        "        'seq_len': seq_len,\n",
        "        'final_train_loss': last.get('train_loss'),\n",
        "        'final_train_acc': last.get('train_acc'),\n",
        "        'final_val_loss': last.get('val_loss') or val_loss,\n",
        "        'final_val_acc': last.get('val_acc') or val_acc,\n",
        "    })\n",
        "    \n",
        "    print(f\"\\nFinal val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(df)\n",
        "df.to_csv('sorting_experiments.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "seqfacben",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
