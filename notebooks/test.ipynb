{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4b23f851",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from seqfacben.generators.random import RandomSequenceGenerator\n",
        "from seqfacben.tasks.sorting import SortingTask\n",
        "from seqfacben.tasks.copy import CopyTask\n",
        "from seqfacben.models.simple_nn import SimpleNN\n",
        "from seqfacben.manager.task_manager import TaskManager\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c41410d8",
      "metadata": {},
      "source": [
        "##### I. Single Combination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "983affb1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100: loss = 4.5627, acc = 0.0000\n",
            "Step 200: loss = 4.4342, acc = 0.0000\n",
            "Step 300: loss = 4.4245, acc = 0.0000\n",
            "Step 400: loss = 4.0265, acc = 0.0000\n",
            "Step 500: loss = 3.9754, acc = 0.0000\n",
            "Step 600: loss = 3.5508, acc = 0.0000\n",
            "Step 700: loss = 3.4714, acc = 0.0000\n",
            "Step 800: loss = 3.1303, acc = 0.0000\n",
            "Step 900: loss = 2.9841, acc = 0.0000\n",
            "Step 1000: loss = 2.8882, acc = 0.0000\n",
            "Step 1100: loss = 2.6664, acc = 0.0000\n",
            "Step 1200: loss = 2.7652, acc = 0.0000\n",
            "Step 1300: loss = 2.7276, acc = 0.0000\n",
            "Step 1400: loss = 2.5291, acc = 0.0000\n",
            "Step 1500: loss = 2.4649, acc = 0.0000\n",
            "Step 1600: loss = 2.3657, acc = 0.0000\n",
            "Step 1700: loss = 2.2465, acc = 0.0000\n",
            "Step 1800: loss = 2.2839, acc = 0.0000\n",
            "Step 1900: loss = 2.2980, acc = 0.0000\n",
            "Step 2000: loss = 2.3256, acc = 0.0000\n",
            "Step 2100: loss = 2.0513, acc = 0.0000\n",
            "Step 2200: loss = 1.9953, acc = 0.0000\n",
            "Step 2300: loss = 1.9070, acc = 0.0000\n",
            "Step 2400: loss = 1.9256, acc = 0.0000\n",
            "Step 2500: loss = 2.0288, acc = 0.0000\n",
            "Step 2600: loss = 1.8615, acc = 0.0000\n",
            "Step 2700: loss = 2.0076, acc = 0.0000\n",
            "Step 2800: loss = 1.9881, acc = 0.0000\n",
            "Step 2900: loss = 1.6012, acc = 0.0000\n",
            "Step 3000: loss = 1.7790, acc = 0.0000\n",
            "Step 3100: loss = 1.8035, acc = 0.0000\n",
            "Step 3200: loss = 1.6973, acc = 0.0000\n",
            "Step 3300: loss = 1.6756, acc = 0.0000\n",
            "Step 3400: loss = 1.7972, acc = 0.0000\n",
            "Step 3500: loss = 1.6569, acc = 0.0000\n",
            "Step 3600: loss = 1.7263, acc = 0.0000\n",
            "Step 3700: loss = 1.6181, acc = 0.0000\n",
            "Step 3800: loss = 1.6057, acc = 0.0000\n",
            "Step 3900: loss = 1.5515, acc = 0.0000\n",
            "Step 4000: loss = 1.6399, acc = 0.0000\n",
            "Step 4100: loss = 1.5884, acc = 0.0000\n",
            "Step 4200: loss = 1.5417, acc = 0.0000\n",
            "Step 4300: loss = 1.6090, acc = 0.0000\n",
            "Step 4400: loss = 1.3948, acc = 0.0000\n",
            "Step 4500: loss = 1.5018, acc = 0.0000\n",
            "Step 4600: loss = 1.5995, acc = 0.0000\n",
            "Step 4700: loss = 1.4906, acc = 0.0000\n",
            "Step 4800: loss = 1.7637, acc = 0.0000\n",
            "Step 4900: loss = 1.4142, acc = 0.0000\n",
            "Step 5000: loss = 1.4337, acc = 0.0000\n",
            "Step 5100: loss = 1.4683, acc = 0.0000\n",
            "Step 5200: loss = 1.4671, acc = 0.0000\n",
            "Step 5300: loss = 1.5376, acc = 0.0000\n",
            "Step 5400: loss = 1.3639, acc = 0.0000\n",
            "Step 5500: loss = 1.4014, acc = 0.0000\n",
            "Step 5600: loss = 1.4707, acc = 0.0000\n",
            "Step 5700: loss = 1.5387, acc = 0.0000\n",
            "Step 5800: loss = 1.3373, acc = 0.0000\n",
            "Step 5900: loss = 1.2824, acc = 0.0000\n",
            "Step 6000: loss = 1.2086, acc = 0.0000\n",
            "Step 6100: loss = 1.3260, acc = 0.0000\n",
            "Step 6200: loss = 1.3666, acc = 0.0000\n",
            "Step 6300: loss = 1.2003, acc = 0.0000\n",
            "Step 6400: loss = 1.3764, acc = 0.0000\n",
            "Step 6500: loss = 1.2784, acc = 0.0000\n",
            "Step 6600: loss = 1.1724, acc = 0.0000\n",
            "Step 6700: loss = 1.0738, acc = 0.0000\n",
            "Step 6800: loss = 1.2627, acc = 0.0000\n",
            "Step 6900: loss = 1.3121, acc = 0.0000\n",
            "Step 7000: loss = 1.0564, acc = 0.0000\n",
            "Step 7100: loss = 1.2537, acc = 0.0000\n",
            "Step 7200: loss = 1.2013, acc = 0.0000\n",
            "Step 7300: loss = 1.2368, acc = 0.0000\n",
            "Step 7400: loss = 1.1144, acc = 0.0000\n",
            "Step 7500: loss = 1.0855, acc = 0.0000\n",
            "Step 7600: loss = 1.2641, acc = 0.0000\n",
            "Step 7700: loss = 1.1506, acc = 0.0000\n",
            "Step 7800: loss = 1.1136, acc = 0.0000\n",
            "Step 7900: loss = 1.2172, acc = 0.0000\n",
            "Step 8000: loss = 1.2422, acc = 0.0000\n",
            "Step 8100: loss = 1.1375, acc = 0.0312\n",
            "Step 8200: loss = 1.0618, acc = 0.0000\n",
            "Step 8300: loss = 1.1738, acc = 0.0000\n",
            "Step 8400: loss = 1.1874, acc = 0.0000\n",
            "Step 8500: loss = 1.1955, acc = 0.0000\n",
            "Step 8600: loss = 1.0945, acc = 0.0000\n",
            "Step 8700: loss = 1.1985, acc = 0.0000\n",
            "Step 8800: loss = 1.0782, acc = 0.0000\n",
            "Step 8900: loss = 1.0246, acc = 0.0312\n",
            "Step 9000: loss = 1.0690, acc = 0.0000\n",
            "Step 9100: loss = 0.9908, acc = 0.0000\n",
            "Step 9200: loss = 1.0422, acc = 0.0000\n",
            "Step 9300: loss = 1.1212, acc = 0.0000\n",
            "Step 9400: loss = 1.0249, acc = 0.0312\n",
            "Step 9500: loss = 1.2016, acc = 0.0000\n",
            "Step 9600: loss = 1.0545, acc = 0.0000\n",
            "Step 9700: loss = 1.0164, acc = 0.0000\n",
            "Step 9800: loss = 1.0458, acc = 0.0312\n",
            "Step 9900: loss = 1.0750, acc = 0.0312\n",
            "Step 10000: loss = 1.0616, acc = 0.0000\n",
            "\n",
            "Testing:\n",
            "Final accuracy: 0.0000\n",
            "\n",
            "Examples:\n",
            "\n",
            "Example 1:\n",
            "  Input:  [95, 67, 63, 132, 181, 72, 64, 98, 75, 32]\n",
            "  Target: [32, 63, 64, 67, 72, 75, 95, 98, 132, 181]\n",
            "  Pred:   [32, 63, 63, 72, 72, 75, 98, 98, 132, 181]\n",
            "  Correct: 7/10\n",
            "\n",
            "Example 2:\n",
            "  Input:  [184, 47, 58, 46, 30, 165, 59, 50, 98, 38]\n",
            "  Target: [30, 38, 46, 47, 50, 58, 59, 98, 165, 184]\n",
            "  Pred:   [30, 38, 47, 47, 50, 55, 98, 98, 165, 184]\n",
            "  Correct: 7/10\n",
            "\n",
            "Example 3:\n",
            "  Input:  [91, 188, 140, 175, 61, 24, 146, 6, 50, 53]\n",
            "  Target: [6, 24, 50, 53, 61, 91, 140, 146, 175, 188]\n",
            "  Pred:   [6, 24, 50, 53, 53, 91, 140, 146, 175, 188]\n",
            "  Correct: 9/10\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Generator parameters\n",
        "vocab_size = 200\n",
        "seq_len = 10\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 64\n",
        "train_steps = 10000\n",
        "\n",
        "# Training loop\n",
        "results = []\n",
        "\n",
        "# Set up and train\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "generator = RandomSequenceGenerator(seq_len, vocab_size)\n",
        "task = CopyTask(generator)\n",
        "task = SortingTask(generator)\n",
        "model = SimpleNN(vocab_size, seq_len, d_model=64).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "manager = TaskManager(task, model, optimizer, device)\n",
        "\n",
        "# Train\n",
        "manager.train(n_steps=10000, batch_size=32)\n",
        "\n",
        "# Test\n",
        "print(\"\\nTesting:\")\n",
        "acc = manager.eval_step(batch_size=32)\n",
        "print(f\"Final accuracy: {acc:.4f}\")\n",
        "\n",
        "manager.show_examples(n_examples=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bdb8dfa",
      "metadata": {},
      "source": [
        "##### II. Multi Experiment Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2bd5480c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Running: vocab_size=5, seq_len=10\n",
            "============================================================\n",
            "Step 500: loss = 0.0130, acc = 0.9688\n",
            "Step 1000: loss = 0.0022, acc = 0.9688\n",
            "Step 1500: loss = 0.0034, acc = 1.0000\n",
            "Step 2000: loss = 0.0005, acc = 1.0000\n",
            "Step 2500: loss = 0.0009, acc = 1.0000\n",
            "Step 3000: loss = 0.0501, acc = 1.0000\n",
            "Step 3500: loss = 0.0013, acc = 1.0000\n",
            "Step 4000: loss = 0.0000, acc = 0.9688\n",
            "Step 4500: loss = 0.0022, acc = 1.0000\n",
            "Step 5000: loss = 0.0001, acc = 1.0000\n",
            "Step 5500: loss = 0.0001, acc = 1.0000\n",
            "Step 6000: loss = 0.0037, acc = 0.9688\n",
            "Step 6500: loss = 0.0003, acc = 1.0000\n",
            "Step 7000: loss = 0.0005, acc = 1.0000\n",
            "Step 7500: loss = 0.0001, acc = 1.0000\n",
            "Step 8000: loss = 0.0003, acc = 0.9688\n",
            "Step 8500: loss = 0.0479, acc = 0.9688\n",
            "Step 9000: loss = 0.0213, acc = 0.9688\n",
            "Step 9500: loss = 0.0796, acc = 0.9375\n",
            "Step 10000: loss = 0.0129, acc = 0.9688\n",
            "\n",
            "Final accuracy: 0.9922\n",
            "\n",
            "============================================================\n",
            "Running: vocab_size=10, seq_len=10\n",
            "============================================================\n",
            "Step 500: loss = 0.1542, acc = 0.9688\n",
            "Step 1000: loss = 0.0235, acc = 0.9688\n",
            "Step 1500: loss = 0.0161, acc = 0.9062\n",
            "Step 2000: loss = 0.0132, acc = 1.0000\n",
            "Step 2500: loss = 0.0031, acc = 0.9688\n",
            "Step 3000: loss = 0.0681, acc = 0.9688\n",
            "Step 3500: loss = 0.0145, acc = 0.9688\n",
            "Step 4000: loss = 0.0033, acc = 0.9688\n",
            "Step 4500: loss = 0.0037, acc = 0.9375\n",
            "Step 5000: loss = 0.0890, acc = 0.9688\n",
            "Step 5500: loss = 0.0159, acc = 0.9688\n",
            "Step 6000: loss = 0.0021, acc = 1.0000\n",
            "Step 6500: loss = 0.0011, acc = 1.0000\n",
            "Step 7000: loss = 0.0272, acc = 0.9062\n",
            "Step 7500: loss = 0.0080, acc = 1.0000\n",
            "Step 8000: loss = 0.0458, acc = 0.8438\n",
            "Step 8500: loss = 0.0001, acc = 1.0000\n",
            "Step 9000: loss = 0.0085, acc = 0.9688\n",
            "Step 9500: loss = 0.0001, acc = 0.9375\n",
            "Step 10000: loss = 0.0063, acc = 0.9062\n",
            "\n",
            "Final accuracy: 0.9688\n",
            "\n",
            "============================================================\n",
            "Running: vocab_size=20, seq_len=10\n",
            "============================================================\n",
            "Step 500: loss = 0.2310, acc = 0.6250\n",
            "Step 1000: loss = 0.1072, acc = 0.7812\n",
            "Step 1500: loss = 0.0450, acc = 0.8750\n",
            "Step 2000: loss = 0.0271, acc = 0.8750\n",
            "Step 2500: loss = 0.0410, acc = 0.9375\n",
            "Step 3000: loss = 0.2772, acc = 0.9062\n",
            "Step 3500: loss = 0.0512, acc = 0.8438\n",
            "Step 4000: loss = 0.0594, acc = 0.9688\n",
            "Step 4500: loss = 0.0604, acc = 0.9062\n",
            "Step 5000: loss = 0.0288, acc = 0.8750\n",
            "Step 5500: loss = 0.0996, acc = 0.7500\n",
            "Step 6000: loss = 0.0309, acc = 0.9375\n",
            "Step 6500: loss = 0.0412, acc = 0.9375\n",
            "Step 7000: loss = 0.0240, acc = 0.8750\n",
            "Step 7500: loss = 0.0958, acc = 0.8750\n",
            "Step 8000: loss = 0.0220, acc = 0.9375\n",
            "Step 8500: loss = 0.1183, acc = 0.8438\n",
            "Step 9000: loss = 0.1195, acc = 0.9688\n",
            "Step 9500: loss = 0.0336, acc = 0.8750\n",
            "Step 10000: loss = 0.0263, acc = 0.9688\n",
            "\n",
            "Final accuracy: 0.8945\n",
            "\n",
            "============================================================\n",
            "Running: vocab_size=5, seq_len=20\n",
            "============================================================\n",
            "Step 500: loss = 0.0056, acc = 0.9688\n",
            "Step 1000: loss = 0.0328, acc = 0.9375\n",
            "Step 1500: loss = 0.0085, acc = 1.0000\n",
            "Step 2000: loss = 0.0387, acc = 0.8125\n",
            "Step 2500: loss = 0.0007, acc = 0.9375\n",
            "Step 3000: loss = 0.0118, acc = 1.0000\n",
            "Step 3500: loss = 0.0001, acc = 1.0000\n",
            "Step 4000: loss = 0.0969, acc = 0.6875\n",
            "Step 4500: loss = 0.0038, acc = 0.9375\n",
            "Step 5000: loss = 0.0003, acc = 0.9688\n",
            "Step 5500: loss = 0.0068, acc = 0.9688\n",
            "Step 6000: loss = 0.0468, acc = 0.9062\n",
            "Step 6500: loss = 0.0002, acc = 1.0000\n",
            "Step 7000: loss = 0.0274, acc = 1.0000\n",
            "Step 7500: loss = 0.0134, acc = 0.9062\n",
            "Step 8000: loss = 0.0000, acc = 1.0000\n",
            "Step 8500: loss = 0.0004, acc = 0.9688\n",
            "Step 9000: loss = 0.0025, acc = 0.9062\n",
            "Step 9500: loss = 0.0005, acc = 0.9688\n",
            "Step 10000: loss = 0.0082, acc = 1.0000\n",
            "\n",
            "Final accuracy: 0.9766\n",
            "\n",
            "============================================================\n",
            "Running: vocab_size=5, seq_len=30\n",
            "============================================================\n",
            "Step 500: loss = 0.0123, acc = 0.9062\n",
            "Step 1000: loss = 0.0051, acc = 0.9375\n",
            "Step 1500: loss = 0.0072, acc = 0.8750\n",
            "Step 2000: loss = 0.0207, acc = 0.9688\n",
            "Step 2500: loss = 0.0299, acc = 0.7812\n",
            "Step 3000: loss = 0.0015, acc = 0.9688\n",
            "Step 3500: loss = 0.0252, acc = 0.8125\n",
            "Step 4000: loss = 0.0060, acc = 0.9688\n",
            "Step 4500: loss = 0.0091, acc = 1.0000\n",
            "Step 5000: loss = 0.0097, acc = 1.0000\n",
            "Step 5500: loss = 0.0236, acc = 0.8750\n",
            "Step 6000: loss = 0.0010, acc = 0.9062\n",
            "Step 6500: loss = 0.0005, acc = 1.0000\n",
            "Step 7000: loss = 0.0572, acc = 0.8125\n",
            "Step 7500: loss = 0.0032, acc = 1.0000\n",
            "Step 8000: loss = 0.0085, acc = 0.9688\n",
            "Step 8500: loss = 0.0005, acc = 1.0000\n",
            "Step 9000: loss = 0.0154, acc = 0.9375\n",
            "Step 9500: loss = 0.0090, acc = 0.9062\n",
            "Step 10000: loss = 0.0002, acc = 1.0000\n",
            "\n",
            "Final accuracy: 0.9648\n",
            "\n",
            "============================================================\n",
            "RESULTS SUMMARY\n",
            "============================================================\n",
            "   vocab_size  seq_len  final_accuracy  final_loss\n",
            "0           5       10        0.992188    0.012893\n",
            "1          10       10        0.968750    0.006277\n",
            "2          20       10        0.894531    0.026318\n",
            "3           5       20        0.976562    0.008225\n",
            "4           5       30        0.964844    0.000184\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Experiment configurations\n",
        "configs = [\n",
        "    {'vocab_size': 5, 'seq_len': 10},\n",
        "    {'vocab_size': 10, 'seq_len': 10},\n",
        "    {'vocab_size': 20, 'seq_len': 10},\n",
        "    {'vocab_size': 5, 'seq_len': 20},\n",
        "    {'vocab_size': 5, 'seq_len': 30},\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for config in configs:\n",
        "    vocab_size = config['vocab_size']\n",
        "    seq_len = config['seq_len']\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running: vocab_size={vocab_size}, seq_len={seq_len}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Setup\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    generator = RandomSequenceGenerator(seq_len, vocab_size)\n",
        "    task = SortingTask(generator)\n",
        "    model = SimpleNN(vocab_size, seq_len, d_model=64).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    manager = TaskManager(task, model, optimizer, device)\n",
        "    \n",
        "    # Train\n",
        "    history = manager.train(n_steps=10000, batch_size=32, eval_every=500)\n",
        "    \n",
        "    # Final evaluation\n",
        "    final_acc = manager.eval_step(batch_size=256)\n",
        "    \n",
        "    # Save results\n",
        "    results.append({\n",
        "        'vocab_size': vocab_size,\n",
        "        'seq_len': seq_len,\n",
        "        'final_accuracy': final_acc,\n",
        "        'final_loss': history[-1]['loss'] if history else None\n",
        "    })\n",
        "    \n",
        "    print(f\"\\nFinal accuracy: {final_acc:.4f}\")\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(df)\n",
        "df.to_csv('sorting_experiments.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "seqfacben",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
